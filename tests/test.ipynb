{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bcddc88",
   "metadata": {},
   "source": [
    "#### This is implemented basis this [tutorial](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/17-langgraph/01-core-features/12-langgraph-conversation-summaries), with custom reducer and checkpoint saver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f7bffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_dynamodb_checkpoint import DynamoDBSaver\n",
    "from typing import Literal, Annotated\n",
    "from langgraph_utils import call_model\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph_reducer import MessagePrunerNode , PrunableStateFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a89b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'reducer_test2' already exists.\n"
     ]
    }
   ],
   "source": [
    "saver = DynamoDBSaver(\n",
    "    table_name=\"reducer_test2\",\n",
    "    max_read_request_units=50,  # Optional, default is 100\n",
    "    max_write_request_units=50,  # Optional, default is 100\n",
    "    ttl_seconds=86400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5d7b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll store both the conversation messages and the summary in the state\n",
    "class State(MessagesState):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a3e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: State) -> Literal[\"summarize_conversation\", END]:\n",
    "    \"\"\"\n",
    "    Check if the conversation is too long (over 6 messages).\n",
    "    If it is, move to the 'summarize_conversation' node.\n",
    "    Otherwise, end the conversation.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d85cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(state: State):\n",
    "    \"\"\"\n",
    "    If a summary of the conversation already exists, we include it as a\n",
    "    system message. Otherwise, we just use the existing messages.\n",
    "    \"\"\"\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    if summary:\n",
    "        system_message = f\"This is the conversation summary so far: {summary}\"\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    response = call_model(\"gpt-4o\", \"openai\", messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4c300ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Create a partially-applied function\n",
    "model_func = partial(call_model, \"gpt-4o\", \"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cddeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db0e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner_node = MessagePrunerNode(min_messages=4, max_messages=6, model_func=model_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db37f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the workflow graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"conversation\", ask_llm)\n",
    "workflow.add_node(\"summarize_conversation\",pruner_node)\n",
    "\n",
    "# Define edges\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile with memory checkpoint\n",
    "app = workflow.compile(checkpointer=saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e2e6b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_update(update):\n",
    "    \"\"\"\n",
    "    Helper function to print out updates during streaming.\n",
    "    \"\"\"\n",
    "    for k, v in update.items():\n",
    "        for m in v.get(\"messages\", []):\n",
    "            m.pretty_print()\n",
    "        if \"summary\" in v:\n",
    "            print(v[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49f9ccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello! Nice to meet you. My name is Junseong.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Junseong! Nice to meet you too. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Do you remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can't remember names or personal details from past interactions. However, I'm here to help with any questions or information you need right now!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am working as an AI researcher.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds exciting! As an AI researcher, you must be involved in cutting-edge projects and exploring innovative technologies. If you have any specific questions or topics you'd like to discuss, feel free to share.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a configuration object with thread ID\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# 1) First user message\n",
    "input_message = HumanMessage(content=\"Hello! Nice to meet you. My name is Junseong.\")\n",
    "input_message.pretty_print()\n",
    "\n",
    "# Process the first message in streaming mode and print updates\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)\n",
    "\n",
    "# 2) Second user message\n",
    "input_message = HumanMessage(content=\"Do you remember my name?\")\n",
    "input_message.pretty_print()\n",
    "\n",
    "# Process the second message in streaming mode and print updates\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)\n",
    "\n",
    "# 3) Third user message\n",
    "input_message = HumanMessage(content=\"I am working as an AI researcher.\")\n",
    "input_message.pretty_print()\n",
    "\n",
    "# Process the third message in streaming mode and print updates\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c25a725c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello! Nice to meet you. My name is Junseong.', additional_kwargs={}, response_metadata={}, id='7a82947e-f2fe-49a5-bc2d-dd5f11eaa064'),\n",
       "  AIMessage(content='Hello Junseong! Nice to meet you too. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 21, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6dd05565ef', 'id': 'chatcmpl-BIxUydDtvkYHQKAxbGXQ5oH93oloT', 'finish_reason': 'stop', 'logprobs': None}, id='run-dec2cbb7-b600-470d-a69f-98b2313a6784-0', usage_metadata={'input_tokens': 21, 'output_tokens': 19, 'total_tokens': 40, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='Do you remember my name?', additional_kwargs={}, response_metadata={}, id='5ca5f269-0449-4533-b580-d8985e6a256c'),\n",
       "  AIMessage(content=\"I can't remember names or personal details from past interactions. However, I'm here to help with any questions or information you need right now!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 53, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6dd05565ef', 'id': 'chatcmpl-BIxV1R3PSD0q7PAFcW6gtqQtwPTih', 'finish_reason': 'stop', 'logprobs': None}, id='run-3289d994-8e2c-4835-9f90-1a618c3bb4bf-0', usage_metadata={'input_tokens': 53, 'output_tokens': 28, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='I am working as an AI researcher.', additional_kwargs={}, response_metadata={}, id='d21e44b1-f08f-4246-b1b6-528ed289acdb'),\n",
       "  AIMessage(content=\"That sounds exciting! As an AI researcher, you must be involved in cutting-edge projects and exploring innovative technologies. If you have any specific questions or topics you'd like to discuss, feel free to share.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 96, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6dd05565ef', 'id': 'chatcmpl-BIxV57eOR7UmXydyh4CEFLM7QzHhX', 'finish_reason': 'stop', 'logprobs': None}, id='run-353a863e-2581-46c6-961e-260cf7a319a1-0', usage_metadata={'input_tokens': 96, 'output_tokens': 41, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = app.get_state(config).values\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48162190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm recently learning more about LLMs. I'm reading the latest papers on LLM.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great! Large Language Models (LLMs) are a rapidly evolving area of AI with numerous advancements and applications. Some recent developments in the field might include enhancements in efficiency, scalability, interpretability, and their use in various applications like natural language processing, understanding, and generation. \n",
      "\n",
      "If you have questions about specific concepts or papers, or if you want a discussion on trending topics in LLMs, feel free to ask!\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "Certainly! We briefly talked about whether I remember names and I explained that I can't retain personal information or details from past interactions. How else may I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Create a new user message\n",
    "input_message = HumanMessage(\n",
    "    content=\"I'm recently learning more about LLMs. I'm reading the latest papers on LLM.\"\n",
    ")\n",
    "\n",
    "# Display the message content\n",
    "input_message.pretty_print()\n",
    "\n",
    "# Process and print updates in streaming mode\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6dc38c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello! Nice to meet you. My name is Junseong.', additional_kwargs={}, response_metadata={}, id='7a82947e-f2fe-49a5-bc2d-dd5f11eaa064'),\n",
       "  HumanMessage(content='I am working as an AI researcher.', additional_kwargs={}, response_metadata={}, id='d21e44b1-f08f-4246-b1b6-528ed289acdb'),\n",
       "  AIMessage(content=\"That sounds exciting! As an AI researcher, you must be involved in cutting-edge projects and exploring innovative technologies. If you have any specific questions or topics you'd like to discuss, feel free to share.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 96, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6dd05565ef', 'id': 'chatcmpl-BIxV57eOR7UmXydyh4CEFLM7QzHhX', 'finish_reason': 'stop', 'logprobs': None}, id='run-353a863e-2581-46c6-961e-260cf7a319a1-0', usage_metadata={'input_tokens': 96, 'output_tokens': 41, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content=\"I'm recently learning more about LLMs. I'm reading the latest papers on LLM.\", additional_kwargs={}, response_metadata={}, id='3c83e03a-270f-40e4-b8b1-672789520bab'),\n",
       "  AIMessage(content=\"That's great! Large Language Models (LLMs) are a rapidly evolving area of AI with numerous advancements and applications. Some recent developments in the field might include enhancements in efficiency, scalability, interpretability, and their use in various applications like natural language processing, understanding, and generation. \\n\\nIf you have questions about specific concepts or papers, or if you want a discussion on trending topics in LLMs, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 162, 'total_tokens': 249, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6dd05565ef', 'id': 'chatcmpl-BIxVqdPZukU5C6iR0lRJHzi6DHCgv', 'finish_reason': 'stop', 'logprobs': None}, id='run-e9f17a96-4923-4036-8f4c-c88ece6641bf-0', usage_metadata={'input_tokens': 162, 'output_tokens': 87, 'total_tokens': 249, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'summary': \"Certainly! We briefly talked about whether I remember names and I explained that I can't retain personal information or details from past interactions. How else may I assist you today?\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the conversation state again to see the new summary\n",
    "values = app.get_state(config).values\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "903c6f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Do you also recall my occupation?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can't retain personal details such as your occupation across interactions. However, based on our current conversation, you've mentioned that you are working as an AI researcher. If there's anything else you'd like to discuss or ask, feel free to let me know!\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "I'm sorry, I can't respond to that.\n"
     ]
    }
   ],
   "source": [
    "# Create another user message asking about the user's occupation\n",
    "input_message = HumanMessage(content=\"Do you also recall my occupation?\")\n",
    "input_message.pretty_print()\n",
    "\n",
    "# Process in streaming mode\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
